{
  "noir_version": "1.0.0-beta.18+99bb8b5cf33d7669adbdef096b12d80f30b4c0c9",
  "hash": "3837055756143027620",
  "abi": {
    "parameters": [
      {
        "name": "deck",
        "type": { "kind": "array", "length": 52, "type": { "kind": "field" } },
        "visibility": "private"
      },
      { "name": "seed", "type": { "kind": "field" }, "visibility": "private" }
    ],
    "return_type": { "abi_type": { "kind": "field" }, "visibility": "private" },
    "error_types": {}
  },
  "bytecode": "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",
  "debug_symbols": "tZjNbuJIFEbfhXUWvrfq1k9eZTSKSEJaSIhEdBhpFOXd28B33J2FLRTUG6pSjg8HU8cgPlbPm8fjj4ft/uX15+r+n4/V42G7221/POxen9bv29f9uPrxebfiz4f3w2YzLq3+OD6e9bY+bPbvq/v9cbe7W/233h3P//Tzbb0/j+/rw3h0uFtt9s/jOAJftrvNafZ59/vsYf7UPETT2XmoMQHCvhBsgdAjRIhh6HMEnyekcAFSr7/P71/OTwvn594BxPAtQi0VQhtijhALV6EZVyG38Ilg1zs0L5NDynMOS++lJ8PBU5t7JxYJliZC1DlCnyeEG68ivJXZ/TTcuB1sYUeOz8u76a3GtxA9iMp7a7OIdPOOWLK4cmNfjXD7FuK6OKz+3Wtxex4ppjyy5dkb1a1b029/R5deRc3szFzbbKK+sDNjbJtGc8zeJzzfeiHi5guxiLhuX/rt+3LRYmFf/jv+tX7aHr586K+G1f14hp0f/fyYzo95fN7xksdlKOMwfjLXy9Aui/0y2HBZNdPoWk8as9ZDY9G6aNY0iueDRvHcNYrnUnPxXHJetS4975f1JL9kl/Ukv5S0Lr+k15rkl+SX5Jfkl+WX5Zfll+WX5Zfll+WX5Zfll+UX8gv5hfxCfiG/kF/IL+QX8gv5FfkV+RX5FfkV+RX5FfkV+RX5FflV+VX5VflV+VX5VflV+VX5VflV+TX5Nfk1+TX5Nfk1+TX5Nfk1+TX5dfl1+XX5dfl1+XX5dfl1+XX59Wk/D0zY0YMzYU8PmQm7eihMKocak04hUypytSkWSxwiFwsOEcxUzJQMzRjRmE8V4kw3RjhGOUY6RjtGPEY9Rj5GP5amwHEmIaMhIyKjIiMjoyMjJKMkIyXL070DZ2oycjJ6MoIyijKSMpoyojKqsphuSzgTllGWkZbRlhGXUZeRl9GXEZiV6Y6HM40ZkRmVGZkZnRmhGaUZqRmtWZ1upjiTm9GbEZxRnJGc0ZwRnVGdkZ3RnRGeUZ6RntGeEZ9Rn5Gf0Z8RoFGg9ekjYPoM4EOABp0GnQadBp0GnQadBp0GnQadBv3UoJ8nziQxyUyCSWFSmTQmXZNTg5cJZIfskB2yQ3bIDtkhO+QEOUFOkBPkBDlBTpAT5AQ5Qc6QM+QMOUPOkDPkDDlDzpAz5IAckANyQA7IATkgB+SAHJAL5AK5QC6QC+RyJn+evjIdtuvH3UY/dbwc909//PLx/v8bR/ht5O3w+rR5Ph42py9M52PjV6hf",
  "file_map": {
    "19": {
      "source": "// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{\n    if crate::runtime::is_unconstrained() {\n        // Temporary measure while Barretenberg is main proving system.\n        // Please open an issue if you're working on another proving system and running into problems due to this.\n        crate::static_assert(\n            N <= 1024,\n            \"Barretenberg cannot prove blake3 hashes with inputs larger than 1024 bytes\",\n        );\n    }\n    __blake3(input)\n}\n\n#[foreign(blake3)]\nfn __blake3<let N: u32>(input: [u8; N]) -> [u8; 32] {}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars, true)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Decompose the input 'bn254 scalar' into two 128 bits limbs.\n// It is called 'unsafe' because it does not assert the limbs are 128 bits\n// Assuming the limbs are 128 bits:\n// Assert the decomposition does not overflow the field size.\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    // Check that the decomposition does not overflow the field size\n    let (a, b) = if xhi == crate::field::bn254::PHI {\n        (xlo, crate::field::bn254::PLO)\n    } else {\n        (xhi, crate::field::bn254::PHI)\n    };\n    crate::field::bn254::assert_lt(a, b);\n\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn poseidon2_permutation<let N: u32>(input: [Field; N], state_len: u32) -> [Field; N] {\n    assert_eq(input.len(), state_len);\n    poseidon2_permutation_internal(input)\n}\n\n#[foreign(poseidon2_permutation)]\nfn poseidon2_permutation_internal<let N: u32>(input: [Field; N]) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { $crate::hash::Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: $crate::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher {\n    type H: Hasher;\n\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    type H = H;\n\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u8 as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u16 as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u32 as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u64 as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n",
      "path": "std/hash/mod.nr"
    },
    "51": {
      "source": "use poseidon::poseidon2::Poseidon2;\nuse std::field::bn254::assert_lt;\n\n/// Number of cards in a standard deck.\npub global DECK_SIZE: u32 = 52;\n\n/// Number of cards to deal for gameplay (5 players * 2 cards + 5 community cards = 15).\npub global CARDS_TO_DEAL: u32 = 15;\n\n// Domain separators prevent cross-protocol hash collisions.\npub global HASH_DOMAIN_SEPARATOR_SEED: Field = 1;\npub global HASH_DOMAIN_SEPARATOR_DECK: Field = 2;\npub global HASH_DOMAIN_SEPARATOR_CARD: Field = 3;\n/// Domain separator for Fisher-Yates RNG state transitions.\npub global HASH_DOMAIN_SEPARATOR_RNG: Field = 4;\npub global PADDING_NONCE: Field = 5;\n\n/// Performs a deterministic Fisher-Yates shuffle on a 52-card deck.\n///\n/// # Arguments\n/// * `seed` - Random seed from on-chain randomness source.\n///\n/// # Returns\n/// A shuffled deck represented as an array of Field elements (0-51).\n///\n/// # Security Properties\n/// - Deterministic: Same seed always produces the same shuffle.\n/// - Uniform: Each permutation is equally likely given a uniformly random seed.\n/// - Verifiable: The shuffle can be independently verified with the seed.\n#[export]\npub fn fisher_yates_shuffle(seed: Field) -> [Field; DECK_SIZE] {\n    // Initialize the deck as 0-51 indices\n    let mut deck = [0; DECK_SIZE];\n    for i in 0..DECK_SIZE {\n        deck[i] = i as Field;\n    }\n\n    // Initialize the RNG state with the random seed using domain separator\n    let mut rng_state = Poseidon2::hash([HASH_DOMAIN_SEPARATOR_RNG, seed], 2);\n\n    // Perform the Fisher-Yates shuffle\n    // Iterate from the last element down to the second element\n    for i in 0..(DECK_SIZE - 1) {\n        let idx = (DECK_SIZE - 1) - i;\n\n        // Generate random hash with domain-separated RNG state update\n        rng_state = Poseidon2::hash([HASH_DOMAIN_SEPARATOR_RNG, rng_state, idx as Field], 3);\n\n        // Calculate the swap index unconstrained\n        let range = (idx + 1) as Field;\n        // Safety: constraints enabled by proceeding assertions\n        let (quotient, remainder) = unsafe { divide_hint(rng_state, range) };\n\n        // Constrain the division result: rng_state = quotient * range + remainder\n        assert(rng_state == quotient * range + remainder);\n        // Ensure remainder is in valid range [0, range)\n        assert_lt(remainder, range);\n\n        let swap_idx = remainder as u32;\n\n        // Perform the swap\n        if swap_idx != idx {\n            let temp = deck[idx];\n            deck[idx] = deck[swap_idx];\n            deck[swap_idx] = temp;\n        }\n    }\n\n    deck\n}\n\n/// Unconstrained hint for field division.\n/// Computes (quotient, remainder) such that numerator = quotient * denominator + remainder.\nunconstrained fn divide_hint(numerator: Field, denominator: Field) -> (Field, Field) {\n    // NOTE: assuming denominator is small enough to fit in u32 (as is the case for a DECK_SIZE of 52)\n    let den_u64 = denominator as u64;\n    // Minimal check to avoid division by zero\n    assert(den_u64 != 0);\n    // Ensure denominator fits in u32 to guarantee 'remainder * 256' fits in u64\n    assert(den_u64 <= 4294967295);\n\n    let bytes: [u8; 32] = numerator.to_be_bytes();\n    let mut remainder: u64 = 0;\n    let mut quotient: Field = 0;\n\n    for i in 0..32 {\n        let b = bytes[i] as u64;\n        let val = remainder * 256 + b;\n        let q_digit = val / den_u64;\n        let r_digit = val % den_u64;\n\n        quotient = quotient * 256 + (q_digit as Field);\n        remainder = r_digit;\n    }\n    (quotient, remainder as Field)\n}\n\n/// Computes the Merkle root of a shuffled deck.\n///\n/// # Arguments\n/// * `deck` - The shuffled deck array.\n/// * `seed` - The shuffle seed (used to derive salt for binding).\n///\n/// # Returns\n/// The Merkle root hash of the deck.\n///\n/// # Implementation Notes\n/// - Uses a 64-leaf tree (52 cards + 12 padding leaves).\n/// - Each card is hashed with its position and a seed-derived salt.\n#[export]\npub fn merkle_root(deck: [Field; DECK_SIZE], seed: Field) -> Field {\n    // Generate salt for binding cards to this specific shuffle\n    let salt = derive_salt(seed);\n\n    // Hash all cards directly into buffer\n    let mut buffer: [Field; 64] = [0; 64];\n\n    for i in 0..DECK_SIZE {\n        buffer[i] = hash_card_in_deck(deck[i], i as Field, salt);\n    }\n\n    // Pad buffer with a fixed value to reach power of 2 tree size\n    let padding = Poseidon2::hash([HASH_DOMAIN_SEPARATOR_DECK, PADDING_NONCE], 2);\n    for i in DECK_SIZE..64 {\n        buffer[i] = padding;\n    }\n\n    // Build tree bottom-up, reusing buffer space\n    // After each level, results are stored in the first half of the buffer\n    let mut size = 64;\n    for _ in 0..6 {\n        let next_size = size / 2;\n        for i in 0..next_size {\n            buffer[i] = merkle_a_pair(buffer[i * 2], buffer[i * 2 + 1]);\n        }\n        size = next_size;\n    }\n\n    buffer[0]\n}\n\n/// Derives a salt from the shuffle seed for card hashing.\npub fn derive_salt(seed: Field) -> Field {\n    Poseidon2::hash([seed, HASH_DOMAIN_SEPARATOR_CARD], 2)\n}\n\n/// Hashes a card at a specific position with salt.\n/// The position ensures uniqueness even for duplicate card values.\npub fn hash_card_in_deck(card: Field, position: Field, salt: Field) -> Field {\n    Poseidon2::hash([HASH_DOMAIN_SEPARATOR_CARD, card, position, salt], 4)\n}\n\n/// Hashes two child nodes to produce a parent node in the Merkle tree.\npub fn merkle_a_pair(left: Field, right: Field) -> Field {\n    Poseidon2::hash([left, right], 2)\n}\n\n/// Extracts the first CARDS_TO_DEAL cards from the shuffled deck.\n///\n/// # Arguments\n/// * `deck` - The shuffled deck array.\n///\n/// # Returns\n/// An array of the first 15 cards for gameplay.\n#[export]\npub fn get_cards(deck: [Field; DECK_SIZE]) -> [Field; CARDS_TO_DEAL] {\n    let mut cards = [0; CARDS_TO_DEAL];\n    for i in 0..CARDS_TO_DEAL {\n        cards[i] = deck[i];\n    }\n    cards\n}\n\n// =============================================================================\n// Test Module\n// =============================================================================\n\nmod tests {\n    use super::{\n        CARDS_TO_DEAL, DECK_SIZE, derive_salt, fisher_yates_shuffle, get_cards, hash_card_in_deck,\n        merkle_a_pair, merkle_root,\n    };\n\n    // -------------------------------------------------------------------------\n    // Fisher-Yates Shuffle Tests\n    // -------------------------------------------------------------------------\n\n    #[test]\n    fn test_shuffle_produces_valid_permutation() {\n        // A valid permutation contains each card exactly once\n        let seed: Field = 12345;\n        let deck = fisher_yates_shuffle(seed);\n\n        // Check that all cards 0-51 appear exactly once\n        let mut card_count: [u32; DECK_SIZE] = [0; DECK_SIZE];\n        for i in 0..DECK_SIZE {\n            let card_idx = deck[i] as u32;\n            assert(card_idx < DECK_SIZE, \"Card index out of bounds\");\n            card_count[card_idx] += 1;\n        }\n\n        for i in 0..DECK_SIZE {\n            assert(card_count[i] == 1, \"Each card must appear exactly once\");\n        }\n    }\n\n    #[test]\n    fn test_shuffle_is_deterministic() {\n        // Same seed must produce the same shuffle\n        let seed: Field = 0xabcdef123456;\n        let deck1 = fisher_yates_shuffle(seed);\n        let deck2 = fisher_yates_shuffle(seed);\n\n        for i in 0..DECK_SIZE {\n            assert(deck1[i] == deck2[i], \"Shuffle must be deterministic\");\n        }\n    }\n\n    #[test]\n    fn test_shuffle_different_seeds_produce_different_decks() {\n        let deck1 = fisher_yates_shuffle(1);\n        let deck2 = fisher_yates_shuffle(2);\n\n        // At least one card should be in a different position\n        let mut has_difference = false;\n        for i in 0..DECK_SIZE {\n            if deck1[i] != deck2[i] {\n                has_difference = true;\n            }\n        }\n        assert(has_difference, \"Different seeds should produce different shuffles\");\n    }\n\n    #[test]\n    fn test_shuffle_with_zero_seed() {\n        // Zero seed should still produce a valid permutation\n        let deck = fisher_yates_shuffle(0);\n\n        let mut card_count: [u32; DECK_SIZE] = [0; DECK_SIZE];\n        for i in 0..DECK_SIZE {\n            let card_idx = deck[i] as u32;\n            card_count[card_idx] += 1;\n        }\n\n        for i in 0..DECK_SIZE {\n            assert(card_count[i] == 1, \"Each card must appear exactly once\");\n        }\n    }\n\n    // -------------------------------------------------------------------------\n    // Merkle Root Tests\n    // -------------------------------------------------------------------------\n\n    #[test]\n    fn test_merkle_root_is_deterministic() {\n        let seed: Field = 42;\n        let deck = fisher_yates_shuffle(seed);\n\n        let root1 = merkle_root(deck, seed);\n        let root2 = merkle_root(deck, seed);\n\n        assert(root1 == root2, \"Merkle root must be deterministic\");\n    }\n\n    #[test]\n    fn test_merkle_root_different_decks_produce_different_roots() {\n        let deck1 = fisher_yates_shuffle(100);\n        let deck2 = fisher_yates_shuffle(200);\n\n        let root1 = merkle_root(deck1, 100);\n        let root2 = merkle_root(deck2, 200);\n\n        assert(root1 != root2, \"Different decks should produce different roots\");\n    }\n\n    #[test]\n    fn test_merkle_root_same_deck_different_seed_produces_different_root() {\n        // The seed affects the salt, so same deck with different seeds = different roots\n        let deck = fisher_yates_shuffle(123);\n\n        let root1 = merkle_root(deck, 123);\n        let root2 = merkle_root(deck, 456);\n\n        assert(root1 != root2, \"Same deck with different seeds should produce different roots\");\n    }\n\n    // -------------------------------------------------------------------------\n    // Helper Function Tests\n    // -------------------------------------------------------------------------\n\n    #[test]\n    fn test_derive_salt_is_deterministic() {\n        let seed: Field = 999;\n        let salt1 = derive_salt(seed);\n        let salt2 = derive_salt(seed);\n\n        assert(salt1 == salt2, \"derive_salt must be deterministic\");\n    }\n\n    #[test]\n    fn test_derive_salt_different_seeds_produce_different_salts() {\n        let salt1 = derive_salt(1);\n        let salt2 = derive_salt(2);\n\n        assert(salt1 != salt2, \"Different seeds should produce different salts\");\n    }\n\n    #[test]\n    fn test_hash_card_is_deterministic() {\n        let card: Field = 10;\n        let position: Field = 5;\n        let salt: Field = 12345;\n\n        let hash1 = hash_card_in_deck(card, position, salt);\n        let hash2 = hash_card_in_deck(card, position, salt);\n\n        assert(hash1 == hash2, \"hash_card_in_deck must be deterministic\");\n    }\n\n    #[test]\n    fn test_hash_card_position_affects_hash() {\n        let card: Field = 10;\n        let salt: Field = 12345;\n\n        let hash1 = hash_card_in_deck(card, 0, salt);\n        let hash2 = hash_card_in_deck(card, 1, salt);\n\n        assert(hash1 != hash2, \"Different positions should produce different hashes\");\n    }\n\n    #[test]\n    fn test_merkle_pair_is_deterministic() {\n        let left: Field = 111;\n        let right: Field = 222;\n\n        let hash1 = merkle_a_pair(left, right);\n        let hash2 = merkle_a_pair(left, right);\n\n        assert(hash1 == hash2, \"merkle_a_pair must be deterministic\");\n    }\n\n    #[test]\n    fn test_merkle_pair_order_matters() {\n        let a: Field = 111;\n        let b: Field = 222;\n\n        let hash1 = merkle_a_pair(a, b);\n        let hash2 = merkle_a_pair(b, a);\n\n        assert(hash1 != hash2, \"merkle_a_pair should be order-sensitive\");\n    }\n\n    // -------------------------------------------------------------------------\n    // Card Selection Tests\n    // -------------------------------------------------------------------------\n\n    #[test]\n    fn test_get_cards_extracts_first_fifteen() {\n        let deck = fisher_yates_shuffle(777);\n        let cards = get_cards(deck);\n\n        for i in 0..CARDS_TO_DEAL {\n            assert(cards[i] == deck[i], \"get_cards should extract cards in order\");\n        }\n    }\n\n    #[test]\n    fn test_get_cards_returns_correct_count() {\n        let deck = fisher_yates_shuffle(888);\n        let cards = get_cards(deck);\n\n        // Verify we get exactly CARDS_TO_DEAL cards\n        assert(cards.len() == CARDS_TO_DEAL, \"Should return CARDS_TO_DEAL cards\");\n    }\n\n    // -------------------------------------------------------------------------\n    // Integration Tests\n    // -------------------------------------------------------------------------\n\n    #[test]\n    fn test_full_shuffle_and_verify_workflow() {\n        // Simulate the full workflow: shuffle, compute root, extract cards\n        let seed: Field = 0xdeadbeef;\n\n        // Step 1: Shuffle\n        let deck = fisher_yates_shuffle(seed);\n\n        // Step 2: Compute merkle root (for on-chain commitment)\n        let root = merkle_root(deck, seed);\n\n        // Step 3: Extract cards for gameplay\n        let cards = get_cards(deck);\n\n        // Verify: Re-compute and check consistency\n        let deck_verify = fisher_yates_shuffle(seed);\n        let root_verify = merkle_root(deck_verify, seed);\n        let cards_verify = get_cards(deck_verify);\n\n        assert(root == root_verify, \"Root should match on re-computation\");\n        for i in 0..CARDS_TO_DEAL {\n            assert(cards[i] == cards_verify[i], \"Cards should match on re-computation\");\n        }\n    }\n}\n",
      "path": "/home/ally/DevEnv/pvtDock/KH/poker-solana/backend/src/services/circuitry/assist/src/lib.nr"
    },
    "59": {
      "source": "use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        self.state[0] += self.cache[0];\n        self.state[1] += self.cache[1];\n        self.state[2] += self.cache[2];\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut state = [0; 4];\n        state[RATE] = iv;\n\n        if std::runtime::is_unconstrained() {\n            for i in 0..(in_len / RATE) {\n                state[0] += input[i * RATE];\n                state[1] += input[i * RATE + 1];\n                state[2] += input[i * RATE + 2];\n                state = crate::poseidon2_permutation(state, 4);\n            }\n\n            // handle remaining elements after last full RATE-sized chunk\n            let remainder_start = (in_len / RATE) * RATE;\n            for j in remainder_start..in_len {\n                state[j - remainder_start] += input[j];\n            }\n        } else {\n            let mut states: [[Field; 4]; N / RATE + 1] = [[0; 4]; N / RATE + 1];\n            states[0] = state;\n\n            // process all full RATE-sized chunks, storing state after each permutation\n            for chunk_idx in 0..(N / RATE) {\n                for i in 0..RATE {\n                    state[i] += input[chunk_idx * RATE + i];\n                }\n                state = crate::poseidon2_permutation(state, 4);\n                states[chunk_idx + 1] = state;\n            }\n\n            // get state at the last full block before in_len\n            let first_partially_filled_chunk = in_len / RATE;\n            state = states[first_partially_filled_chunk];\n\n            // handle remaining elements after last full RATE-sized chunk\n            let remainder_start = (in_len / RATE) * RATE;\n            for j in 0..RATE {\n                let idx = remainder_start + j;\n                if idx < in_len {\n                    state[j] += input[idx];\n                }\n            }\n        }\n\n        // always run final permutation unless we just completed a full chunk\n        // still need to permute once if in_len is 0\n        if (in_len == 0) | (in_len % RATE != 0) {\n            state = crate::poseidon2_permutation(state, 4)\n        };\n\n        state[0]\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n",
      "path": "/home/ally/nargo/github.com/noir-lang/poseidon/v0.2.2/src/poseidon2.nr"
    }
  },
  "expression_width": { "Bounded": { "width": 4 } }
}
